{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a63d7f5-6f96-4736-ab45-5eabaa7c1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a8148171-020b-4415-bcdc-f4f29ca08564",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a674c116-688e-4ab1-843a-c9957b82c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = keras.Sequential([\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "])\n",
    "x = augmentation(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fc2cfc07-3318-44ed-ae59-ad1d9e65ea3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "39f0313f-9e13-403c-a2e3-9dec082f2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0843de3c-f1c6-4c88-9f88-1ef198167262",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.MaxPooling2D(pool_size=2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a61be084-90b4-4c82-b45c-f137a83038a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4a491d60-c5e9-4cd1-8d79-881240cbffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a1fa35f-2a1d-4748-a331-7b9f1d13f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d0102ba9-9ce0-46f7-8e33-a6a97ad7ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "867b54fc-0988-4266-998a-14d42faf732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a89d5e59-87e2-4f06-9102-d7a6fb75e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b6292f11-da2e-4d23-a174-573f5a823259",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "363c2f6c-32bb-41da-a6d4-7ec777958915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dfcaaf0e-091c-4720-87c8-ae022c3456ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.2706 - accuracy: 0.9143\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 0.0920 - accuracy: 0.9717\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0679 - accuracy: 0.9785\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0592 - accuracy: 0.9818\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0525 - accuracy: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb00962b4f0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "02f24177-7346-42b4-b0e8-fdc703ebe63b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 7.9495 - accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.949492931365967, 0.9869999885559082]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ca567f3e-06d9-4b5c-9760-0c71f0e95621",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.preprocessing.image.load_img(\"img.png\", color_mode=\"grayscale\", target_size=(28, 28), interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "599afe07-e8f4-496e-899a-1d52d9249cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a50160eb-4a21-4021-8e47-ae704a870928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb008972550>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e6e477e0-e9be-4b64-8b42-492a3216d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape([1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8a11e2d-f26b-461d-9d5e-de8ed339c23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14af2f8a-1972-421a-9a59-66da0beae12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = '0002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2c93d6-bd3c-4e4f-b917-762ba057d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'digits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ae2153-56f7-4996-9411-6ec0bbd3011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_name, model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2eddf7d-4ed8-40a4-a0bf-a3131c1134eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 11:34:20.669616: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Failed to add concrete function 'b'__inference_model_layer_call_fn_23446'' to object-based SavedModel as it captures tensor <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>> which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gn/t94ndfqs7js134qsvnvsznsw0000gn/T/ipykernel_88599/3192530043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/function_serialization.py\u001b[0m in \u001b[0;36mserialize_concrete_function\u001b[0;34m(concrete_function, node_ids, coder)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mbound_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     raise KeyError(\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;34mf\"Failed to add concrete function '{concrete_function.name}' to object-\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34mf\"based SavedModel as it captures tensor {capture!r} which is unsupported\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Failed to add concrete function 'b'__inference_model_layer_call_fn_23446'' to object-based SavedModel as it captures tensor <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>> which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).\""
     ]
    }
   ],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5020bb-2a3b-446d-b237-32646ff26816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 12:31:45.664570: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "cnn = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5188de8-62a4-47da-abe6-79bee0724f86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gn/t94ndfqs7js134qsvnvsznsw0000gn/T/ipykernel_91368/762255131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "cnn.predict(train_images[0], batch_size=None).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba4447d-29ae-4dc1-8d49-55e47eddaa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aidanfarnum/Documents/digrec'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c0882357-2130-4d5a-985a-87aed99247b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.predict(image).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63d0f0a9-884e-42a3-90e3-17f8b8d43b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b2ed76b-3e54-4dfe-9f5d-e57a58046df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 12:33:43.444632: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/aidanfarnum/Documents/diglet/orig_cnn/0001/assets\n"
     ]
    }
   ],
   "source": [
    "cnn.save('/Users/aidanfarnum/Documents/diglet/orig_cnn/0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39816698-3865-4368-9057-1520ac0b4965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
