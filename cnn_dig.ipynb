{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a63d7f5-6f96-4736-ab45-5eabaa7c1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8148171-020b-4415-bcdc-f4f29ca08564",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2cfc07-3318-44ed-ae59-ad1d9e65ea3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2021-12-17 00:17:28.180678: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-12-17 00:17:28.181004: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
    }
   ],
   "source": [
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f0313f-9e13-403c-a2e3-9dec082f2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0843de3c-f1c6-4c88-9f88-1ef198167262",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.MaxPooling2D(pool_size=2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61be084-90b4-4c82-b45c-f137a83038a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a491d60-c5e9-4cd1-8d79-881240cbffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a1fa35f-2a1d-4748-a331-7b9f1d13f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0102ba9-9ce0-46f7-8e33-a6a97ad7ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "867b54fc-0988-4266-998a-14d42faf732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a89d5e59-87e2-4f06-9102-d7a6fb75e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6292f11-da2e-4d23-a174-573f5a823259",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363c2f6c-32bb-41da-a6d4-7ec777958915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfcaaf0e-091c-4720-87c8-ae022c3456ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "2021-12-17 00:17:38.176977: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\nEpoch 1/5\n938/938 [==============================] - 20s 21ms/step - loss: 0.3516 - accuracy: 0.8862\nEpoch 2/5\n938/938 [==============================] - 20s 21ms/step - loss: 0.0469 - accuracy: 0.9852\nEpoch 3/5\n938/938 [==============================] - 21s 22ms/step - loss: 0.0304 - accuracy: 0.9909\nEpoch 4/5\n938/938 [==============================] - 21s 22ms/step - loss: 0.0226 - accuracy: 0.9936\nEpoch 5/5\n938/938 [==============================] - 21s 22ms/step - loss: 0.0173 - accuracy: 0.9947\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fc3b26d67c0>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02f24177-7346-42b4-b0e8-fdc703ebe63b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "313/313 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9923\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.026762021705508232, 0.9922999739646912]"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca567f3e-06d9-4b5c-9760-0c71f0e95621",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.preprocessing.image.load_img(\"img.png\", color_mode=\"grayscale\", target_size=(28, 28), interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "599afe07-e8f4-496e-899a-1d52d9249cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a50160eb-4a21-4021-8e47-ae704a870928",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 1 - image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e6e477e0-e9be-4b64-8b42-492a3216d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape([1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f8a11e2d-f26b-461d-9d5e-de8ed339c23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14af2f8a-1972-421a-9a59-66da0beae12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = '0002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f2c93d6-bd3c-4e4f-b917-762ba057d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'digits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96ae2153-56f7-4996-9411-6ec0bbd3011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_name, model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2eddf7d-4ed8-40a4-a0bf-a3131c1134eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: digits/0002/assets\n"
    }
   ],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a5020bb-2a3b-446d-b237-32646ff26816",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5188de8-62a4-47da-abe6-79bee0724f86",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "cnn.predict(test_images[0].reshape((1, 28, 28))).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4447d-29ae-4dc1-8d49-55e47eddaa39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}